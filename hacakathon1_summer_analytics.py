# -*- coding: utf-8 -*-
"""Hacakathon1_summer_analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14oQNwpBY1AcXqNXfoVcyVmWcEaMVWVqs

***SUBMITTED BY- HIMANSHI LALWANI
     email: hlalwani1705@gmail.com***
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Summary of dataset:
#Dataset
#Each row in the dataset contains:

#class: Ground truth label of the land cover type â€” one of {Water, Impervious, Farm, Forest, Grass, Orchard}

#ID:Unique identifier for the sample

#27 NDVI Time Points: Columns labeled in the format YYYYMMDD_N (e.g., 20150720_N, 20150602_N) represent NDVI values collected on different dates. These values form a time series representing vegetation dynamics for each location.

df= pd.read_csv('/content/hacktrain.csv')
df['class'].value_counts()

df

df.isnull().sum()

df.drop(columns=['ID'],inplace=True)
df

sns.heatmap(df.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns)
# we cannot skip all the col or rows cause we will end up skipping the whole dataset

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import r2_score
from sklearn.impute import SimpleImputer

label_encoder = LabelEncoder()
df1 = label_encoder.fit_transform(df['class'])
df['class'] = df1
df.head()

X = df.drop(columns=['class'])
y = df['class']

imputer = SimpleImputer(strategy='mean') # You can change the strategy (e.g., 'median', 'most_frequent')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

X = df_imputed.drop(columns=['class'])
y = df_imputed['class']
# %%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100) # Increased max_iter
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

# PREDICTIONS BY LOGISTIC, DT AND RANDOM FOREST
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
clf1= LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100)
clf2= DecisionTreeClassifier()
clf3= RandomForestClassifier()
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

clf1.fit(X_train, y_train)
clf2.fit(X_train, y_train)
clf3.fit(X_train, y_train)

y_pred1= clf1.predict(X_test)
#y_pred1= y_pred1.astype(int)
y_pred2= clf2.predict(X_test)
y_pred3= clf3.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report
print('Logistic Regression')
print('train test accuracy: ', accuracy_score(y_test, y_pred1))
print(classification_report(y_test, y_pred1))
print('*************************')
print('Decision Tree')
print('train test accuracy: ', accuracy_score(y_test, y_pred2))
print(classification_report(y_test, y_pred2))
print('*************************')
print('Random Forest')
print('train test accuracy: ', accuracy_score(y_test, y_pred3))
print(classification_report(y_test, y_pred3))

df_test= pd.read_csv('/content/hacktest.csv')

df_test



ID = df_test['ID']
df_test.drop(columns=['ID'],inplace=True)

y_pred_1= clf1.predict(df_test)
y_pred_1= y_pred_1.astype(int)
y_pred_2= clf2.predict(df_test)
y_pred_2= y_pred_2.astype(int)
y_pred_3= clf3.predict(df_test)
y_pred_3= y_pred_3.astype(int)

print(y_pred_1)
print(y_pred_2)
print(y_pred_3)

y_lr = label_encoder.inverse_transform(y_pred_1)
y_dt = label_encoder.inverse_transform(y_pred_2)
y_rf = label_encoder.inverse_transform(y_pred_3)
# Use np.unique() for numpy arrays
#print(np.unique(y_lr))

result = pd.DataFrame({
    'ID':ID,
    'class-LR': y_dt
})
result

result.to_csv("submission_himanshi_2.csv", index=False)